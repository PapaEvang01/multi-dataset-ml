Phase 3B.1 â€” Global Model Explainability (Feature Importance)

Phase Overview
--------------
Phase 3B.1 moves beyond performance metrics and error counts to analyze how the
models make decisions at a global level. The objective of this phase is to
understand which input features are most influential in the overall prediction
process.

Using the exact model configurations and tuned thresholds established in Phase 2,
this phase applies permutation feature importance to both the SVM (RBF kernel)
and Random Forest models.

Methodology
-----------
Permutation feature importance evaluates model reliance on individual features
by randomly shuffling one feature at a time and measuring the resulting drop in
performance. A larger performance drop indicates a stronger dependence on that
feature.

This approach is model-agnostic and suitable for both linear and non-linear
classifiers, making it appropriate for a fair comparison between SVM and
Random Forest.

Evaluation Perspectives
-----------------------
Feature importance is analyzed with respect to two complementary objectives:

- Overall accuracy, reflecting general classification performance
- Malignant recall (sensitivity), which is clinically critical and directly
  related to reducing false negatives

Evaluating both perspectives allows us to distinguish between features that
optimize global correctness and those that specifically support reliable
detection of malignant tumors.

Key Insights
------------
The results provide global interpretability, showing that both models rely
primarily on medically meaningful features related to tumor shape, size, and
boundary irregularity. Features associated with concavity, texture, and
measurement variability consistently emerge as influential.

These findings validate that the learned decision logic aligns with known
clinical indicators of malignancy and is not driven by spurious correlations.

Role Within the Pipeline
------------------------
Phase 3B.1 establishes global trust in the models by confirming that their
predictions are grounded in meaningful feature patterns. This global
explainability analysis serves as a necessary foundation for Phase 3B.2, which
focuses on local, per-sample explanations of difficult and ambiguous cases.
