FROM MNIST TO THE REAL WORLD
Evaluating and Adapting Digit Recognition Models Beyond the Dataset

---

PROJECT OVERVIEW

This project studies the gap between benchmark datasets and real-world data
using handwritten digit recognition as a case study.

A Convolutional Neural Network (CNN) is trained on the MNIST dataset and 
then evaluated on real-world digit images collected manually (paint-drawn and handwritten). 
The goal is to demonstrate that high benchmark accuracy does not necessarily 
translate to real-world robustness and to explore systematic ways to adapt a model to out-of-distribution data.

---

OBJECTIVES

* Train a strong CNN baseline on MNIST
* Evaluate the trained model on real-world digit images
* Design a robust OpenCV-based preprocessing pipeline
* Quantify performance before and after adaptation
* Apply fine-tuning and mixed training strategies
* Analyze failure cases and model limitations

---

DATASETS

1. MNIST (Benchmark Dataset)

* 60,000 training images
* 10,000 test images
* Grayscale images, 28x28 resolution
* Digit classes from 0 to 9

2. Real-World Digits (Custom Dataset)

A small dataset collected manually and stored in Google Drive:

* Paint digits (mouse-drawn, clean background)
* Handwritten digits (pen on paper, photographed)

Total images: approximately 20
Purpose: simulate out-of-distribution (OOD) data

---

METHODOLOGY

The project is divided into three main phases.

---

PHASE 1 — MNIST BASELINE TRAINING

Model:

* Convolutional Neural Network with two convolution blocks
* Fully connected classifier head
* Dropout for regularization

Training setup:

* Optimizer: Adam
* Loss function: CrossEntropyLoss
* Epochs: 10
* Input normalization using MNIST mean and standard deviation

Result:

* MNIST test accuracy around 99%
* Stable convergence and no overfitting

This phase confirms that the model learns the MNIST distribution effectively.

---

PHASE 2 — REAL-WORLD EVALUATION AND PREPROCESSING

Problem:
When applying the MNIST-trained model directly to real-world images, performance drops significantly.
The model often produces high-confidence but incorrect predictions, especially on handwritten photographs.

Solution:
A custom OpenCV preprocessing pipeline is implemented to convert real-world 
images into MNIST-like inputs. The pipeline includes:

* Grayscale conversion
* Contrast normalization using CLAHE
* Adaptive or Otsu thresholding
* Morphological operations to clean noise
* Contour filtering to remove paper edges and shadows
* Digit centering using center-of-mass
* Final normalization to 28x28 resolution

Each image is:

* Safely processed with error handling
* Visualized (original vs processed)
* Logged and exported for inspection

---

PHASE 3 — FINE-TUNING AND MIXED TRAINING

A) Real-World Fine-Tuning

* Convolutional layers frozen
* Classifier head unfrozen
* Strong geometric and noise augmentations
* Very low learning rate
* Short training schedule

B) Mixed Fine-Tuning (MNIST + Real-World)

* Alternating training batches:

  * MNIST subset batches
  * Real-world digit batches
* All layers unfrozen
* Extremely low learning rate
* Prevents catastrophic forgetting of MNIST features

---

RESULTS AND ANALYSIS

Real-World Accuracy Summary

PHASE 1 — MNIST
- Test accuracy ≈ 99%
- Stable training and strong baseline performance

PHASE 2 — REAL-WORLD (NO RETRAINING)
- Overall accuracy ≈ 52%
- Paint digits ≈ 80%
- Handwritten digits ≈ 22%
- Significant performance drop due to domain shift

PHASE 3 — FINE-TUNING
- Real-world-only fine-tuning: limited gains
- Mixed MNIST + real-world fine-tuning:
  - Paint accuracy ≈ 90%
  - Handwritten accuracy ≈ 89%
  - Best overall real-world performance

---

KEY OBSERVATIONS

* Paint digits are easier and already close to the MNIST distribution
* Handwritten photographs represent the main challenge
* Preprocessing quality has a larger impact than model complexity
* Fine-tuning improves robustness but is limited by dataset size
* The model often makes confident mistakes on out-of-distribution inputs

These behaviors closely reflect real-world machine learning deployment scenarios.

---

LIMITATIONS

* Very small real-world dataset
* Limited variation in writing styles and lighting
* Simple CNN architecture by design
* No advanced domain adaptation techniques applied

---

FUTURE IMPROVEMENTS

* Collect a larger real-world handwritten dataset
* Add perspective and illumination correction
* Explore domain adaptation and self-supervised learning
* Compare CNN performance with transformer-based models
* Deploy the system as a real-time digit recognition tool

---

WHY THIS PROJECT MATTERS

This project is not focused on achieving high MNIST accuracy.

Instead, it demonstrates:

* Proper evaluation discipline
* Awareness of distribution shift
* Practical computer vision preprocessing
* Careful experimentation and analysis
* A real-world engineering mindset

---

TECHNOLOGY STACK

* Python
* PyTorch
* OpenCV
* NumPy and Pandas
* Matplotlib and Seaborn
* Google Colab

---

AUTHOR

Evangelos Papaioannou
Electrical and Computer Engineering Graduate

